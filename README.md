## COM6012 Scalable Machine Learning - University of Sheffield

### Spring 2021 by Haiping Lu (1-5) and Mauricio A √Ålvarez (6-10)

This edition uses [**PySpark 3.0.1**](https://spark.apache.org/docs/latest/api/python/index.html#), the [latest stable release of Spark](https://spark.apache.org/releases/spark-release-3-0-1.html) (Sep 02, 2020).

* Session 1: Introduction to Spark and HPC
* Session 2: RDD, DataFrame, ML pipeline, & parallelization
* Session 3: Scalable matrix factorisation for collaborative filtering in recommender systems
* Session 4: Scalable K-means clustering
* Session 5: Scalable PCA for dimensionality reduction and data types in Spark
* Session 6: Advanced decision trees
* Session 7: Scalable logistic regression
* Session 8: Scalable generalized linear models
* Session 9: Scalable neural networks
* Session 10: Apache Spark in the Cloud (guest lecture by [Dr Michael Smith)](http://www.michaeltsmith.org.uk/?page_id=11)

You can also download the [Spring 2020 version](https://github.com/haipinglu/ScalableML/archive/v2020.zip) for preview or reference.

### Acknowledgement

The materials are built with references to the following sources:

* The official [Apach Spark documentations](https://spark.apache.org/). *Note: the **latest information** is here.*
* The [PySpark tutorial](https://runawayhorse001.github.io/LearningApacheSpark/) by [Wenqiang Feng](http://web.utk.edu/~wfeng1/) with [PDF - Learning Apache Spark with Python Release v1.0](https://runawayhorse001.github.io/LearningApacheSpark/pyspark.pdf). Also see [GitHub Project Page](https://github.com/runawayhorse001/LearningApacheSpark). *Note: last update in Feb 2020.*
* The [**Introduction to Apache Spark** course by A. D. Joseph, University of California, Berkeley](https://www.edx.org/course/introduction-apache-spark-uc-berkeleyx-cs105x). *Note: archived.*

Many thanks to

* Mike Croucher, Neil Lawrence, Will Furnass, Twin Karmakharm, and Vamsi Sai Turlapati for their inputs and inspirations since 2016.
* Our teaching assistants and students who have contributed in many ways since 2017.
